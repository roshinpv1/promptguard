# PromptGuard Environment Variables
# Copy this file to .env and update with your values
# cp .env.example .env

# =============================================================================
# LLM Backend Selection
# =============================================================================
# Set USE_LM_STUDIO=true to use LM Studio (local)
# Set USE_LM_STUDIO=false (or unset) to use Google Gemini (cloud)
USE_LM_STUDIO=false

# =============================================================================
# Google Gemini Configuration (when USE_LM_STUDIO=false)
# =============================================================================
# Get your API key from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# =============================================================================
# LM Studio Configuration (when USE_LM_STUDIO=true)
# =============================================================================
# Base URL for LM Studio API (default: http://localhost:1234/v1)
# Make sure LM Studio Local Server is running on this port
LM_STUDIO_URL=http://localhost:1234/v1

# Model name identifier (can be any name, LM Studio uses the loaded model)
LM_STUDIO_MODEL=local-model
